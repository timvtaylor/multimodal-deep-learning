{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":112899,"databundleVersionId":13449579,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:11:36.135316Z","iopub.execute_input":"2025-09-17T03:11:36.135762Z","iopub.status.idle":"2025-09-17T03:13:57.421096Z","shell.execute_reply.started":"2025-09-17T03:11:36.135737Z","shell.execute_reply":"2025-09-17T03:13:57.419776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:13:57.423592Z","iopub.execute_input":"2025-09-17T03:13:57.423933Z","iopub.status.idle":"2025-09-17T03:14:04.334187Z","shell.execute_reply.started":"2025-09-17T03:13:57.423912Z","shell.execute_reply":"2025-09-17T03:14:04.333561Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load train and test data into dataframes\ntry:\n    train_df = pd.read_csv('/kaggle/input/grand-xray-slam-division-a/train1.csv')\n    print(f\"Loaded train1.csv with {len(train_df)} rows\")\nexcept FileNotFoundError:\n    print(\"Error: train1.csv not found. Ensure dataset is attached.\")\n    raise\n\ntry:\n    test_df = pd.read_csv('/kaggle/input/grand-xray-slam-division-a/sample_submission_1.csv')\n    print(f\"Loaded sample_submission_1.csv with {len(test_df)} rows\")\nexcept FileNotFoundError:\n    print(\"Error: sample_submission_1.csv not found. Ensure dataset is attached.\")\n    raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:14:04.334949Z","iopub.execute_input":"2025-09-17T03:14:04.335367Z","iopub.status.idle":"2025-09-17T03:14:04.709925Z","shell.execute_reply.started":"2025-09-17T03:14:04.335343Z","shell.execute_reply":"2025-09-17T03:14:04.709201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.io import decode_image\nfrom torch.utils.data import Dataset\nimport torchvision.transforms.v2 as transforms\nfrom torchvision.transforms import Grayscale\n\nlabels = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n\n# Define a custom dataset for the images\nclass XRAYDataset(Dataset):\n    def __init__(self, df, labels, img_dir='/kaggle/input/grand-xray-slam-division-a/train1/'):\n        self.labels = df[labels].copy()\n        self.img_paths = df[['Image_name']].copy()\n        self.img_dir = img_dir\n        \n        self.tab_data = df[['Sex', 'Age', 'ViewCategory', 'ViewPosition']].copy()\n        mean_age = self.tab_data['Age'].mean()\n        self.tab_data['Sex'] = self.tab_data['Sex'].fillna(0.5)\n        self.tab_data['Age'] = self.tab_data['Age'].fillna(mean_age)\n        self.tab_data = pd.get_dummies(self.tab_data)\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_paths.iloc[idx, 0])\n        image = decode_image(img_path)\n        label = self.labels.iloc[idx].to_numpy()\n\n        # Resize and grayscale the images\n        resize_transform = transforms.Resize((256, 256))\n        grayscale_transform = Grayscale(num_output_channels=3)\n        # Handle 1 channel immages\n        if(image.shape[0]==1):\n            image = grayscale_transform(image).repeat(3, 1, 1)\n        image = resize_transform(image)\n\n        tabular = self.tab_data.iloc[idx].to_numpy()\n        \n        return image, tabular.astype(float), label\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:14:04.711479Z","iopub.execute_input":"2025-09-17T03:14:04.711701Z","iopub.status.idle":"2025-09-17T03:14:04.804499Z","shell.execute_reply.started":"2025-09-17T03:14:04.711685Z","shell.execute_reply":"2025-09-17T03:14:04.803941Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_xray_dataset = XRAYDataset(df=train_df, labels=labels)\nfig = plt.figure()\n# Visualize the first 4 xray images\nfor i, item in enumerate(train_xray_dataset):\n    print(type(item[1]))\n    ax = plt.subplot(1, 4, i + 1)\n    ax.axis('off')\n    plt.imshow(item[0].permute(1, 2, 0)) # permute to make it a numpy image from tensor\n\n    if i == 3:\n        plt.show()\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:14:04.805119Z","iopub.execute_input":"2025-09-17T03:14:04.805431Z","iopub.status.idle":"2025-09-17T03:14:05.623056Z","shell.execute_reply.started":"2025-09-17T03:14:04.805411Z","shell.execute_reply":"2025-09-17T03:14:05.622420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Instantiate DataLoader\nbatch_size=64\ntrain_dataloader = DataLoader(train_xray_dataset, batch_size=batch_size,\n                        shuffle=True, num_workers=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:14:05.623915Z","iopub.execute_input":"2025-09-17T03:14:05.624391Z","iopub.status.idle":"2025-09-17T03:14:05.628094Z","shell.execute_reply.started":"2025-09-17T03:14:05.624362Z","shell.execute_reply":"2025-09-17T03:14:05.627403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display image and label.\ntrain_images, train_tabulars, train_labels = next(iter(train_dataloader))\nprint(f\"Image batch shape: {train_images.size()}\")\nprint(f\"Tabular batch shape: {train_tabulars.size()}\")\nprint(f\"Labels batch shape: {train_labels.size()}\")\nimg = train_images[0].squeeze()\nlabel = train_labels[0]\nplt.imshow(img.permute(1, 2, 0))\nplt.show()\nprint(f\"Label: {label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:14:05.628703Z","iopub.execute_input":"2025-09-17T03:14:05.628880Z","iopub.status.idle":"2025-09-17T03:14:12.484331Z","shell.execute_reply.started":"2025-09-17T03:14:05.628865Z","shell.execute_reply":"2025-09-17T03:14:12.483743Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Basic Block:\n# A block that is used multiple times in the original ResNet18 architecture.\n# It consists of:\n# 2 convolutions with a 3x3 kernel as well as a skip/residual connection.\n# Following each convolution is a batch normalization and ReLU activation.\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride):\n        super(BasicBlock, self).__init__()\n        \n        # Skip connection\n        self.skip = nn.Sequential()\n        # If the stride isn't 1 add a convolution to the skip connection to ensure the dimensions match\n        if(not in_channels == out_channels):\n            self.skip = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(num_features=out_channels))\n            \n        # First convolution\n        # Note: we omit the bias term since it is included in the batch normalization\n        self.conv_1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.batch_norm_1 = nn.BatchNorm2d(num_features = out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        \n        # Second convolution\n        self.conv_2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.batch_norm_2 = nn.BatchNorm2d(num_features = out_channels)\n\n    \n    def forward(self, x):\n        # First convolutional block\n        out = self.conv_1(x)\n        out = self.batch_norm_1(out)\n        out = self.relu(out)\n\n        # Second convolutional block\n        out = self.conv_2(out)\n        out = self.batch_norm_2(out)\n\n        # Skip connection\n        out = out + self.skip(x)\n        out = self.relu(out)\n\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T03:14:12.484978Z","iopub.execute_input":"2025-09-17T03:14:12.485256Z","iopub.status.idle":"2025-09-17T03:14:12.491790Z","shell.execute_reply.started":"2025-09-17T03:14:12.485225Z","shell.execute_reply":"2025-09-17T03:14:12.491071Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResNet18(nn.Module):\n    def __init__(self):\n        super(ResNet18, self).__init__()\n        self.in_channels = 64\n\n        # 1) MLP Branch for Tabular Input:\n        self.f1 = nn.Linear(in_features=10, out_features = 12)\n        self.f2 = nn.Linear(in_features=12, out_features = 12)\n        self.f3 = nn.Linear(in_features=12, out_features = 12)\n        self.f4 = nn.Linear(in_features=12, out_features = 14)\n        \n        # 2) Convolutional Branch for Image Input:\n        # Initial convolutional block\n        self.conv_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.batchnorm = nn.BatchNorm2d(num_features=64)\n        self.relu = nn.ReLU(inplace=True)\n        \n        # Sequence of BasicBlocks\n        self.stage_1 = self.residual_stage(BasicBlock, out_channels=64, stride=1)\n        self.stage_2 = self.residual_stage(BasicBlock, out_channels=128, stride=2)\n        self.stage_3 = self.residual_stage(BasicBlock, out_channels=256, stride=2)\n        self.stage_4 = self.residual_stage(BasicBlock, out_channels=512, stride=2)\n\n        # Output layers\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(in_features=512, out_features=14)\n        self.merge1 = nn.Linear(in_features=28, out_features = 28)\n        self.merge2 = nn.Linear(in_features=28, out_features = 34)\n        self.merge3 = nn.Linear(in_features=34, out_features = 14)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x_img, x_tab):\n        # We implement two branches to handle the multi-modality of the data\n        # 1) MLP for the tabular data\n        out_tab = self.relu(self.f1(x_tab))\n        out_tab = self.relu(self.f2(out_tab))\n        out_tab = self.relu(self.f3(out_tab))\n        out_tab = self.relu(self.f4(out_tab))\n        \n        # 2) Convolutional branch for the image\n        # Initial convolutional block\n        out_img = self.conv_1(x_img)\n        out_img = self.batchnorm(out_img)\n        out_img = self.relu(out_img)\n\n        # 4 stages of basic blocks\n        out_img = self.stage_1(out_img)\n        out_img = self.stage_2(out_img)\n        out_img = self.stage_3(out_img)\n        out_img = self.stage_4(out_img)\n\n        # Average pool and flatten to complete image feature extraction\n        out_img = self.avg_pool(out_img)\n        out_img = torch.flatten(out_img, 1)\n        out_img = self.relu(self.fc(out_img))\n\n        # Merge both branches\n        out = torch.cat((out_img, out_tab), 1)\n        out = self.relu(self.merge1(out))\n        out = self.relu(self.merge2(out))\n        out = self.merge3(out)\n        out = self.sigmoid(out)\n        \n        return out\n\n    def residual_stage(self, basicblock, out_channels, stride):\n        basicblock_1 = basicblock(in_channels=self.in_channels, out_channels=out_channels, stride=stride)\n        self.in_channels = out_channels\n        basicblock_2 = basicblock(in_channels=self.in_channels, out_channels=out_channels, stride=1)\n        return nn.Sequential(basicblock_1, basicblock_2)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T04:22:50.919304Z","iopub.execute_input":"2025-09-17T04:22:50.919859Z","iopub.status.idle":"2025-09-17T04:22:50.929884Z","shell.execute_reply.started":"2025-09-17T04:22:50.919834Z","shell.execute_reply":"2025-09-17T04:22:50.929061Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim as optim\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)\n# Train our network\nResNet = ResNet18().to(device)\n\nloss_fn = nn.BCELoss()\noptimizer = torch.optim.Adam(ResNet.parameters(), lr=1e-3)\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (img, tab, y) in enumerate(dataloader):\n        img, tab, y = img.to(device), tab.to(device), y.to(device)\n\n        # Compute prediction error\n        pred = model(img.float(), tab.float())\n        loss = loss_fn(pred, y.float())\n\n        # Backpropagation\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), (batch + 1) * len(img)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n\n\nepochs = 5\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, ResNet, loss_fn, optimizer)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T04:22:55.833072Z","iopub.execute_input":"2025-09-17T04:22:55.833879Z","execution_failed":"2025-09-17T15:11:18.034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save model\ntorch.save(ResNet.state_dict(), '/kaggle/working/DualNetResNet18v1.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T04:19:31.399686Z","iopub.status.idle":"2025-09-17T04:19:31.399926Z","shell.execute_reply.started":"2025-09-17T04:19:31.399819Z","shell.execute_reply":"2025-09-17T04:19:31.399829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load model\n#state_dict = torch.load('/kaggle/working/DualNetResNet18.pt')\n#ResNet.load_state_dict(state_dict)\n#ResNet.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T04:19:31.401515Z","iopub.status.idle":"2025-09-17T04:19:31.401844Z","shell.execute_reply.started":"2025-09-17T04:19:31.401689Z","shell.execute_reply":"2025-09-17T04:19:31.401704Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_xray_dataset = XRAYDataset(df=test_df, labels=labels,  img_dir='/kaggle/input/grand-xray-slam-division-a/test1/')\ntest_dataloader = DataLoader(test_xray_dataset, num_workers=0)\n\ncorrect = 0\ntotal = 0\n# since we're not training, we don't need to calculate the gradients for our outputs\npredictions = []\nwith torch.no_grad():\n    for image, tabular, label in test_dataloader:\n        outputs = ResNet(image.float().to(device), tabular.float().to(device))\n        #outputs = torch.sigmoid(outputs)\n        outputs = torch.round(outputs)\n        predictions.append(outputs.cpu().numpy())\n        total += label.size(1)\n        correct += (outputs.to(device) == label.to(device)).sum().item()\nclass_acc = (correct/total)*100\nprint(f'% Test Data correctly classified: {class_acc}')\n\n# Combine predictions\npredictions = np.vstack(predictions)\npredictions = predictions[:len(test_df)]\n\n# Create submission file\nsubmission_df = test_df.copy()\nsubmission_df[labels] = predictions\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submission file created: submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T15:57:41.737205Z","iopub.execute_input":"2025-09-17T15:57:41.737448Z","iopub.status.idle":"2025-09-17T15:57:41.806023Z","shell.execute_reply.started":"2025-09-17T15:57:41.737419Z","shell.execute_reply":"2025-09-17T15:57:41.804875Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"* Change to non grayscale images\n* Drop unnecessary variables (study, view category)","metadata":{}},{"cell_type":"markdown","source":"**Ideas to improve accuracy**\n* Start with 256*256 images or even larger\n* Less convolutional layers?\n* Need to study popular CNN architecture\n* Add fully connected layers\n* DRAFT AN ARCHITECTURE THEN TEST USING KAGGLE GPU","metadata":{}}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":112899,"databundleVersionId":13449579,"sourceType":"competition"},{"sourceId":585888,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":437825,"modelId":454466},{"sourceId":586821,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":438625,"modelId":455202}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load train and test data into dataframes\ntry:\n    train_df = pd.read_csv('/kaggle/input/grand-xray-slam-division-a/train1.csv')\n    print(f\"Loaded train1.csv with {len(train_df)} rows\")\nexcept FileNotFoundError:\n    print(\"Error: train1.csv not found. Ensure dataset is attached.\")\n    raise\n\ntry:\n    test_df = pd.read_csv('/kaggle/input/grand-xray-slam-division-a/sample_submission_1.csv')\n    print(f\"Loaded sample_submission_1.csv with {len(test_df)} rows\")\nexcept FileNotFoundError:\n    print(\"Error: sample_submission_1.csv not found. Ensure dataset is attached.\")\n    raise","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Variable Selection ##\nThe training data gives us access to metadata about the X-ray images, however, it is important to note that this metadata is not available in the test data. This shapes our overall approach which will use joint learning to extract meaningful features about the metadata from the X-ray image. First, we have to see which metadata variables are meaningfully associated with the response.","metadata":{}},{"cell_type":"code","source":"labels = [\n    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n]\n\nmetadata_vars = [\n    'Sex', 'Age', 'ViewCategory', 'ViewPosition'\n]\n\nY = train_df[labels].copy()\nmetadata = train_df[metadata_vars].copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.io import decode_image\nfrom torch.utils.data import Dataset\nimport torchvision.transforms.v2 as transforms\nfrom torchvision.transforms import Grayscale\n\n# Define a custom dataset for the images\nclass XRAYDataset(Dataset):\n    def __init__(self, df, labels, transform, img_dir='/kaggle/input/grand-xray-slam-division-a/train1/'):\n        self.transform = transform\n        self.labels = df[labels].copy()\n        self.img_paths = df[['Image_name']].copy()\n        self.img_dir = img_dir\n        \n        self.tab_data = df[['Sex', 'Age', 'ViewCategory', 'ViewPosition']].copy()\n        mean_age = self.tab_data['Age'].mean()\n        self.tab_data['Sex'] = self.tab_data['Sex'].fillna(0.5)\n        self.tab_data['Age'] = self.tab_data['Age'].fillna(mean_age)\n        self.tab_data = pd.get_dummies(self.tab_data)\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_paths.iloc[idx, 0])\n        image = decode_image(img_path)\n        label = self.labels.iloc[idx].to_numpy()\n\n        # Convert image to color if grayscale\n        grayscale_transform = Grayscale(num_output_channels=3)\n        if(image.shape[0]==1):\n            image = grayscale_transform(image).repeat(3, 1, 1)\n\n        # Apply transforms to image\n        image = self.transform(image)\n\n        tabular = self.tab_data.iloc[idx].to_numpy()\n        tabular = torch.from_numpy(tabular.astype(float))\n        \n        return image, tabular, label\n    \n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.RandomRotation(degrees=10),  # Randomly rotate by up to 10 degrees\n    transforms.Resize((224, 224)), # Resize to 224x224\n    transforms.Compose([transforms.ToImage(), transforms.ToDtype(torch.float32, scale=True)]), # Convert to PyTorch Tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize\n])\n\ntrain_xray_dataset = XRAYDataset(df=train_df, labels=labels, transform=transform)\nfig = plt.figure()\n# Visualize the first 4 xray images\nfor i, item in enumerate(train_xray_dataset):\n    print(type(item[1]))\n    ax = plt.subplot(1, 4, i + 1)\n    ax.axis('off')\n    plt.imshow(item[0].permute(1, 2, 0)) # permute to make it a numpy image from tensor\n\n    if i == 3:\n        plt.show()\n        break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Instantiate DataLoader\nbatch_size=64\ntrain_dataloader = DataLoader(train_xray_dataset, batch_size=batch_size,\n                        shuffle=True, num_workers=0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display image and label.\ntrain_images, train_tabulars, train_labels = next(iter(train_dataloader))\nprint(f\"Image batch shape: {train_images.size()}\")\nprint(f\"Tabular batch shape: {train_tabulars.size()}\")\nprint(f\"Labels batch shape: {train_labels.size()}\")\nimg = train_images[0].squeeze()\nlabel = train_labels[0]\nplt.imshow(img.permute(1, 2, 0))\nplt.show()\nprint(f\"Label: {label}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Basic Block:\n# A block that is used multiple times in the original ResNet18 architecture.\n# It consists of:\n# 2 convolutions with a 3x3 kernel as well as a skip/residual connection.\n# Following each convolution is a batch normalization and ReLU activation.\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride):\n        super(BasicBlock, self).__init__()\n        \n        # Skip connection\n        self.skip = nn.Sequential()\n        # If the stride isn't 1 add a convolution to the skip connection to ensure the dimensions match\n        if(not in_channels == out_channels):\n            self.skip = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(num_features=out_channels))\n            \n        # First convolution\n        # Note: we omit the bias term since it is included in the batch normalization\n        self.conv_1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.batch_norm_1 = nn.BatchNorm2d(num_features = out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        \n        # Second convolution\n        self.conv_2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.batch_norm_2 = nn.BatchNorm2d(num_features = out_channels)\n\n    \n    def forward(self, x):\n        # First convolutional block\n        out = self.conv_1(x)\n        out = self.batch_norm_1(out)\n        out = self.relu(out)\n\n        # Second convolutional block\n        out = self.conv_2(out)\n        out = self.batch_norm_2(out)\n\n        # Skip connection\n        out = out + self.skip(x)\n        out = self.relu(out)\n\n        return out","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResNet18(nn.Module):\n    def __init__(self):\n        super(ResNet18, self).__init__()\n        self.in_channels = 64\n\n        # 1) Linear Branch for Tabular Input:\n        # Input size: 10\n        # Output size: 32\n        self.tab_branch = nn.Sequential(\n            nn.Linear(in_features=10, out_features=64),\n            nn.ReLU(),\n            nn.Dropout(p=0.),\n            nn.Linear(in_features=64, out_features=128),\n            nn.ReLU()\n        )\n        \n        # 2) Convolutional Branch for Image Input:\n        # Initial convolutional block\n        self.conv_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.batchnorm = nn.BatchNorm2d(num_features=64)\n        self.relu = nn.ReLU(inplace=True)\n        \n        # Sequence of BasicBlocks\n        self.stage_1 = self.residual_stage(BasicBlock, out_channels=64, stride=1)\n        self.stage_2 = self.residual_stage(BasicBlock, out_channels=128, stride=2)\n        self.stage_3 = self.residual_stage(BasicBlock, out_channels=256, stride=2)\n        self.stage_4 = self.residual_stage(BasicBlock, out_channels=512, stride=2)\n\n        # Output layers\n        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(in_features=512, out_features=128)\n        self.merge1 = nn.Linear(in_features=256, out_features = 128)\n        self.dropout1 = nn.Dropout(p=0.3)\n        self.merge2 = nn.Linear(in_features=128, out_features = 64)\n        self.dropout2 = nn.Dropout(p=0.3)\n        self.merge3 = nn.Linear(in_features=64, out_features = 14)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x_img, x_tab):\n        # We implement two branches to handle the multi-modality of the data\n        # 1) MLP for the tabular data\n        out_tab = self.tab_branch(x_tab)\n        \n        # 2) Convolutional branch for the image\n        # Initial convolutional block\n        out_img = self.conv_1(x_img)\n        out_img = self.batchnorm(out_img)\n        out_img = self.relu(out_img)\n\n        # 4 stages of basic blocks\n        out_img = self.stage_1(out_img)\n        out_img = self.stage_2(out_img)\n        out_img = self.stage_3(out_img)\n        out_img = self.stage_4(out_img)\n\n        # Average pool and flatten to complete image feature extraction\n        out_img = self.avg_pool(out_img)\n        out_img = torch.flatten(out_img, 1)\n        out_img = self.fc(out_img)\n        out_img = self.relu(out_img)\n\n        # 3) Merge both branches with a final sequence of linear layers\n        out = torch.cat((out_img, out_tab), 1)\n        out = self.merge1(out)\n        out = self.relu(out)\n        out = self.dropout1(out)\n        \n        out = self.merge2(out)\n        out = self.relu(out)\n        out = self.dropout2(out)\n        \n        out = self.merge3(out)\n        #out = self.sigmoid(out)\n        \n        return out\n\n    def residual_stage(self, basicblock, out_channels, stride):\n        basicblock_1 = basicblock(in_channels=self.in_channels, out_channels=out_channels, stride=stride)\n        self.in_channels = out_channels\n        basicblock_2 = basicblock(in_channels=self.in_channels, out_channels=out_channels, stride=1)\n        return nn.Sequential(basicblock_1, basicblock_2)\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim as optim\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)\n# Train our network\nResNet = ResNet18().to(device)\n\nloss_fn = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.AdamW(ResNet.parameters(), lr=1e-4)\n\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (img, tab, y) in enumerate(dataloader):\n        img, tab, y = img.to(device), tab.to(device), y.to(device)\n\n        # Compute prediction error\n        pred = model(img.float(), tab.float())\n        loss = loss_fn(pred, y.float())\n\n        # Backpropagation\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), (batch + 1) * len(img)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n\n\nepochs = 5\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, ResNet, loss_fn, optimizer)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save model\n#torch.save(ResNet.state_dict(), '/kaggle/working/DualNetResNet18v2.pt')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load model\n\n#state_dict = torch.load('/kaggle/input/eva-x-small/pytorch/default/1/eva_x_small_patch16_merged520k_mim.pt', map_location=device)\n#eva_x_small.load_state_dict(state_dict)\n#model.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(test_df.head)\ntest_xray_dataset = XRAYDataset(df=test_df, labels=labels,  img_dir='/kaggle/input/grand-xray-slam-division-a/test1/')\ntest_dataloader = DataLoader(test_xray_dataset, num_workers=0)\n\ncorrect = 0\ntotal = 0\n# since we're not training, we don't need to calculate the gradients for our outputs\npredictions = []\nwith torch.no_grad():\n    for image, tabular, label in test_dataloader:\n        outputs = ResNet(image.float().to(device), tabular.float().to(device))\n        outputs = torch.sigmoid(outputs)\n        outputs = torch.round(outputs)\n        predictions.append(outputs.to(device).numpy())\n        total += label.size(1)\n        correct += (outputs.to(device) == label.to(device)).sum().item()\nclass_acc = (correct/total)*100\nprint(f'% Test Data correctly classified: {class_acc}')\n\npredictions = np.vstack(predictions)\npredictions = predictions[:len(test_df)]\n\n# Create submission file\nsubmission_df = test_df.copy()\nsubmission_df[labels] = predictions\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submission file created: submission.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
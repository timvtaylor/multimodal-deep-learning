{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load train and test data into dataframes\n",
    "try:\n",
    "    train_df = pd.read_csv('/kaggle/input/grand-xray-slam-division-a/train1.csv')\n",
    "    print(f\"Loaded train1.csv with {len(train_df)} rows\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: train1.csv not found. Ensure dataset is attached.\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    test_df = pd.read_csv('/kaggle/input/grand-xray-slam-division-a/sample_submission_1.csv')\n",
    "    print(f\"Loaded sample_submission_1.csv with {len(test_df)} rows\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: sample_submission_1.csv not found. Ensure dataset is attached.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum',\n",
    "    'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion',\n",
    "    'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices'\n",
    "]\n",
    "\n",
    "metadata_vars = [\n",
    "    'Sex', 'Age', 'ViewCategory', 'ViewPosition'\n",
    "]\n",
    "\n",
    "Y = train_df[labels].copy()\n",
    "metadata = train_df[metadata_vars].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision.io import decode_image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torchvision.transforms import Grayscale\n",
    "\n",
    "# Define a custom dataset for the images\n",
    "class XRAYDataset(Dataset):\n",
    "    def __init__(self, df, labels, transform, img_dir='/kaggle/input/grand-xray-slam-division-a/train1/'):\n",
    "        self.transform = transform\n",
    "        self.labels = df[labels].copy()\n",
    "        self.img_paths = df[['Image_name']].copy()\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "        self.tab_data = df[['Sex', 'Age', 'ViewCategory', 'ViewPosition']].copy()\n",
    "        mean_age = self.tab_data['Age'].mean()\n",
    "        self.tab_data['Sex'] = self.tab_data['Sex'].fillna(0.5)\n",
    "        self.tab_data['Age'] = self.tab_data['Age'].fillna(mean_age)\n",
    "        self.tab_data = pd.get_dummies(self.tab_data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_paths.iloc[idx, 0])\n",
    "        image = decode_image(img_path)\n",
    "        label = self.labels.iloc[idx].to_numpy()\n",
    "\n",
    "        # Convert image to color if grayscale\n",
    "        grayscale_transform = Grayscale(num_output_channels=3)\n",
    "        if(image.shape[0]==1):\n",
    "            image = grayscale_transform(image).repeat(3, 1, 1)\n",
    "\n",
    "        # Apply transforms to image\n",
    "        image = self.transform(image)\n",
    "\n",
    "        tabular = self.tab_data.iloc[idx].to_numpy()\n",
    "        tabular = torch.from_numpy(tabular.astype(float))\n",
    "        \n",
    "        return image, tabular, label\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=10),  # Randomly rotate by up to 10 degrees\n",
    "    transforms.Resize((224, 224)), # Resize to 224x224\n",
    "    transforms.Compose([transforms.ToImage(), transforms.ToDtype(torch.float32, scale=True)]), # Convert to PyTorch Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Normalize\n",
    "])\n",
    "\n",
    "train_xray_dataset = XRAYDataset(df=train_df, labels=labels, transform=transform)\n",
    "fig = plt.figure()\n",
    "# Visualize the first 4 xray images\n",
    "for i, item in enumerate(train_xray_dataset):\n",
    "    print(type(item[1]))\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    ax.axis('off')\n",
    "    plt.imshow(item[0].permute(1, 2, 0)) # permute to make it a numpy image from tensor\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Instantiate DataLoader\n",
    "batch_size=64\n",
    "train_dataloader = DataLoader(train_xray_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_images, train_tabulars, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Image batch shape: {train_images.size()}\")\n",
    "print(f\"Tabular batch shape: {train_tabulars.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_images[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Basic Block:\n",
    "# A block that is used multiple times in the original ResNet18 architecture.\n",
    "# It consists of:\n",
    "# 2 convolutions with a 3x3 kernel as well as a skip/residual connection.\n",
    "# Following each convolution is a batch normalization and ReLU activation.\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        # Skip connection\n",
    "        self.skip = nn.Sequential()\n",
    "        # If the stride isn't 1 add a convolution to the skip connection to ensure the dimensions match\n",
    "        if(not in_channels == out_channels):\n",
    "            self.skip = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(num_features=out_channels))\n",
    "            \n",
    "        # First convolution\n",
    "        # Note: we omit the bias term since it is included in the batch normalization\n",
    "        self.conv_1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.batch_norm_1 = nn.BatchNorm2d(num_features = out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Second convolution\n",
    "        self.conv_2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batch_norm_2 = nn.BatchNorm2d(num_features = out_channels)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # First convolutional block\n",
    "        out = self.conv_1(x)\n",
    "        out = self.batch_norm_1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # Second convolutional block\n",
    "        out = self.conv_2(out)\n",
    "        out = self.batch_norm_2(out)\n",
    "\n",
    "        # Skip connection\n",
    "        out = out + self.skip(x)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        # 1) Linear Branch for Tabular Input:\n",
    "        # Input size: 10\n",
    "        # Output size: 32\n",
    "        self.tab_branch = nn.Sequential(\n",
    "            nn.Linear(in_features=10, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.),\n",
    "            nn.Linear(in_features=64, out_features=128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # 2) Convolutional Branch for Image Input:\n",
    "        # Initial convolutional block\n",
    "        self.conv_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batchnorm = nn.BatchNorm2d(num_features=64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Sequence of BasicBlocks\n",
    "        self.stage_1 = self.residual_stage(BasicBlock, out_channels=64, stride=1)\n",
    "        self.stage_2 = self.residual_stage(BasicBlock, out_channels=128, stride=2)\n",
    "        self.stage_3 = self.residual_stage(BasicBlock, out_channels=256, stride=2)\n",
    "        self.stage_4 = self.residual_stage(BasicBlock, out_channels=512, stride=2)\n",
    "\n",
    "        # Output layers\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(in_features=512, out_features=128)\n",
    "        self.merge1 = nn.Linear(in_features=256, out_features = 128)\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        self.merge2 = nn.Linear(in_features=128, out_features = 64)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        self.merge3 = nn.Linear(in_features=64, out_features = 14)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x_img, x_tab):\n",
    "        # We implement two branches to handle the multi-modality of the data\n",
    "        # 1) MLP for the tabular data\n",
    "        out_tab = self.tab_branch(x_tab)\n",
    "        \n",
    "        # 2) Convolutional branch for the image\n",
    "        # Initial convolutional block\n",
    "        out_img = self.conv_1(x_img)\n",
    "        out_img = self.batchnorm(out_img)\n",
    "        out_img = self.relu(out_img)\n",
    "\n",
    "        # 4 stages of basic blocks\n",
    "        out_img = self.stage_1(out_img)\n",
    "        out_img = self.stage_2(out_img)\n",
    "        out_img = self.stage_3(out_img)\n",
    "        out_img = self.stage_4(out_img)\n",
    "\n",
    "        # Average pool and flatten to complete image feature extraction\n",
    "        out_img = self.avg_pool(out_img)\n",
    "        out_img = torch.flatten(out_img, 1)\n",
    "        out_img = self.fc(out_img)\n",
    "        out_img = self.relu(out_img)\n",
    "\n",
    "        # 3) Merge both branches with a final sequence of linear layers\n",
    "        out = torch.cat((out_img, out_tab), 1)\n",
    "        out = self.merge1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        out = self.merge2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        out = self.merge3(out)\n",
    "        #out = self.sigmoid(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def residual_stage(self, basicblock, out_channels, stride):\n",
    "        basicblock_1 = basicblock(in_channels=self.in_channels, out_channels=out_channels, stride=stride)\n",
    "        self.in_channels = out_channels\n",
    "        basicblock_2 = basicblock(in_channels=self.in_channels, out_channels=out_channels, stride=1)\n",
    "        return nn.Sequential(basicblock_1, basicblock_2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "# Train our network\n",
    "ResNet = ResNet18().to(device)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(ResNet.parameters(), lr=1e-4)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (img, tab, y) in enumerate(dataloader):\n",
    "        img, tab, y = img.to(device), tab.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(img.float(), tab.float())\n",
    "        loss = loss_fn(pred, y.float())\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(img)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, ResNet, loss_fn, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "#torch.save(ResNet.state_dict(), '/kaggle/working/DualNetResNet18v2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(test_df.head)\n",
    "test_xray_dataset = XRAYDataset(df=test_df, labels=labels,  img_dir='/kaggle/input/grand-xray-slam-division-a/test1/')\n",
    "test_dataloader = DataLoader(test_xray_dataset, num_workers=0)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for image, tabular, label in test_dataloader:\n",
    "        outputs = ResNet(image.float().to(device), tabular.float().to(device))\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        outputs = torch.round(outputs)\n",
    "        predictions.append(outputs.to(device).numpy())\n",
    "        total += label.size(1)\n",
    "        correct += (outputs.to(device) == label.to(device)).sum().item()\n",
    "class_acc = (correct/total)*100\n",
    "print(f'% Test Data correctly classified: {class_acc}')\n",
    "\n",
    "predictions = np.vstack(predictions)\n",
    "predictions = predictions[:len(test_df)]\n",
    "\n",
    "# Create submission file\n",
    "submission_df = test_df.copy()\n",
    "submission_df[labels] = predictions\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file created: submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13449579,
     "sourceId": 112899,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 454466,
     "modelInstanceId": 437825,
     "sourceId": 585888,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 455202,
     "modelInstanceId": 438625,
     "sourceId": 586821,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
